# -*- coding: utf-8 -*-
"""Assignment 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HbsUAihdjTIwqp6NBDfxCoEo2o8sW7Da
"""

#importing the required libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 

import seaborn as sns
from numpy import array
from sklearn.preprocessing import LabelEncoder

from google.colab import drive
drive.mount("/content/drive")

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report

df = pd.read_csv("/content/drive/My Drive/datasets_13996_18858_WA_Fn-UseC_-Telco-Customer-Churn.csv")
#create the dataframe
df_1 = pd.DataFrame(data=df)
#print the dataframe
print('\n\nTeleco-customer-churn[1]', df_1)

df_1.shape

df_1.head

df_1.describe

df_1['Churn'].unique()

#1st indetifying Churnning Ratio
df_1['Churn'].value_counts().plot(kind ='barh', figsize =(8,6))
plt.xlabel ('Count', labelpad=14)
plt.ylabel('Count of TARGET Variable per category', y = 1.02 );

100*df_1['Churn'].value_counts()/len(df_1['Churn'])

df_1['Churn'].value_counts()

"""Data is highly imbalanced, ratio = 73:27
So we analyse the data with other features while taking values seperatley to get some insights
"""

Telco_df = df_1.copy()

#converting total charges to numeric data type
Telco_df.TotalCharges = pd.to_numeric(Telco_df.TotalCharges, errors ='coerce')
Telco_df.isnull().sum()   #checking missing values and finding the total

Telco_df.loc[Telco_df['TotalCharges'].isnull()== True]

"""since the % of the missing values of Total Charges is very low compare to the dataset, it is safe to ignore them further processing

"""

#Removing missing values
Telco_df.dropna(how='any', inplace = True)

#calculating correlations
Telco_df.corr()

"""Inserting Customers into groups based on Tenure"""

print(Telco_df.tenure.max())  #finding maximum months for Tenure

#therefore grouping into groups of 12, to get 6 groups
labels =['{0} - {1}'.format(i, i +11) for i in range( 1, 72, 12 )]
Telco_df['tenure_group']= pd.cut(Telco_df.tenure, range(1, 80, 12), right =False, labels=labels )

Telco_df['tenure_group'].value_counts()

"""Remove columns not required / not necessary for the processing"""

Telco_df.drop(columns=['customerID', 'tenure'], axis= 1, inplace = True)
Telco_df.head()

"""Visualisation of data"""

for i, predictor in enumerate(Telco_df.drop(columns = ['Churn', 'TotalCharges', 'MonthlyCharges'])):
  plt.figure(i)
  sns.countplot(data= Telco_df, x= predictor, hue = 'Churn')

"""Categorical Variable Encoding

Encoding all the categorial variables into dummy variables

Convert the target variable "Churn" in binary numerical variable i.e. Yes =1 ; No =0
"""

Telco_df['Churn'] = np.where(Telco_df.Churn == 'Yes', 1 , 0)

Telco_df.head()

Telco_df_dummies = pd.get_dummies(Telco_df)
Telco_df_dummies.head()

"""Relationship between Monthly Charges and Total Charges"""

sns.lmplot(data=Telco_df_dummies , x = 'MonthlyCharges', y ='TotalCharges', fit_reg = False)

"""Churn by Monthly Charges and Total Charges"""

Mth = sns.kdeplot(Telco_df_dummies.MonthlyCharges[(Telco_df_dummies["Churn"] == 0)],
                  color ='Red',shade =True)
Mth = sns.kdeplot(Telco_df_dummies.MonthlyCharges[(Telco_df_dummies['Churn']== 1)],
                  ax = Mth, color ='Blue', shade =True)
Mth.legend(['No Churn', 'Churn'], loc ='upper right')
Mth.set_ylabel('Density')
Mth.set_xlabel('Monthly Charges')
Mth.set_title('Monthly charges churn')

"""*Build a correlation of all predictions with 'Churn'*"""

plt.figure(figsize =(20,8))
Telco_df_dummies.corr()['Churn'].sort_values(ascending =False).plot(kind ='bar')

df= Telco_df_dummies.copy()

from sklearn.model_selection import train_test_split

#creating X and Y Variables
x= df.drop('Churn', axis =1 )
print(x)

#creating  X & Y variables
y = df['Churn']
y

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size =0.2, random_state =0)

"""XGBOOST MODEL"""

#getting the dataset ready
import xgboost as xgb
from xgboost import XGBClassifier
xgb_model = xgb.XGBClassifier(max_depth=5, learning_rate=0.08, objective= 
            'binary:logistic',n_jobs=-1).fit(x_train, y_train)
xgb_model

#Accuracy of XGBOOST on training set
xgb_model.score(x_train, y_train)

"""Train the Model with the training test"""

from xgboost import plot_importance
fig, ax = plt.subplots(figsize=(10,8))
plot_importance(xgb_model, ax=ax)

"""Saving the model and loading the model"""

from sklearn.externals import joblib
joblib.dump(classification, 'classifier.pkl')

